{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install beautifulsoup4\n",
    "#pip install requests\n",
    "#pip install lxml\n",
    "#pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making Empty Dataframe\n",
    "data = pd.DataFrame(columns = [\"Sno.\",\"CIN_number\",\"Name\",\"Status\",\"Address\",\"Email\",\"Category\",\"Class\",\"Age\",\"sector\"])\n",
    "a = [\"AHMEDABAD\",\"JAIPUR\",\"INDORE\",\"LUCKNOW\",\"THANE\",\"GURGAON\",\"PATNA\",\"SURAT\",\"COIMBATORE\",\"NAGPUR\",\"HOWRAH\",\"CHANDIGARH\",\"PUNE\",\"KANPUR\",\"BHOPAL\",\"VADODARA\",\"GUWAHATI\",\"AGRA\",\"RAIPUR\",\"NASHIK\",\"RAJKOT\",\"LUDHIANA\",\"NOIDA\",\"AURANGABAD\",\"GHAZIABAD\",\"FARIDABAD\",\"UDAIPUR\",\"VISAKHAPATNAM\",\"THRISSUR\",\"RANCHI\",\"TRIVANDRUM\",\"GWALIOR\",\"GOA\",\"VARANASI\",\"KOLHAPUR\",\"SILIGURI\",\"KOCHI\",\"Cuttack\",\"COCHIN\",\"VIJAYAWADA\",\"BHUBANESWAR\",\"DELHI\",\"MUMBAI\",\"KOLKATA\",\"BANGALORE\",\"HYDERABAD\",\"CHENNAI\"]\n",
    "buck =[\"F\",\"G\",\"H\",\"I\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    path = \"C:\\\\Users\\\\jaske\\\\OneDrive\\\\Desktop\\\\{}.xlsx\".format(i)\n",
    "    data.to_excel(path)\n",
    "    for j in buck:\n",
    "        value = 1\n",
    "        website = \"https://www.zaubacorp.com/company-list/city-\"+i+\"/paidup-\"+j+\"/p-1-company.html\"\n",
    "        b = []\n",
    "    #For Iterations\n",
    "        try:\n",
    "            web = requests.get(website).text\n",
    "            soup1 = BeautifulSoup(web, \"lxml\")\n",
    "            section = soup1.find(\"div\", class_ = \"back\")\n",
    "            tion = section.find(\"div\", class_ = \"region region-content\")\n",
    "            sect = tion.find(\"section\", {\"id\":\"block-system-main\",\"class\":\"block block-system clearfix\"})\n",
    "            sec = sect.find(\"div\").find_all(\"div\")\n",
    "            for se in sec:\n",
    "                se = se.find_all(\"span\")\n",
    "                for s in se:\n",
    "                    b.append(s.text)\n",
    "            c = b[0].split(\" \")\n",
    "            num = c[-1]\n",
    "\n",
    "            site = \"https://www.zaubacorp.com/company-list/city-\"+i+\"/paidup-\"+j+\"/p-{}-company.html\"\n",
    "            for l in range(1,int(num)+1):\n",
    "        #Getting Main URL\n",
    "                source = requests.get(site.format(l)).text\n",
    "                soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "        #Getting Links\n",
    "                x = soup.find(\"table\", class_ = \"table table-striped col-md-12 col-sm-12 col-xs-12\")\n",
    "                jobs = x.find_all(\"a\", href = True)\n",
    "                for job in jobs:\n",
    "                    try:\n",
    "                        link = job[\"href\"]\n",
    "                        url = requests.get(link).text\n",
    "                        soup2 = BeautifulSoup(url,\"lxml\")\n",
    "\n",
    "            #Collecting Data\n",
    "                        x = soup2.find(\"table\", class_ = \"table table-striped\")\n",
    "                        body = x.find(\"tbody\")\n",
    "                        trs = body.find_all(\"tr\")\n",
    "\n",
    "                        count = 0 \n",
    "\n",
    "                        for tr in trs:\n",
    "                            tds = tr.find_all(\"td\")\n",
    "                            for td in tds:\n",
    "                                ps = td.find_all(\"p\")\n",
    "                                for p in ps:\n",
    "                                    count = count+1\n",
    "                                    if(count == 2):\n",
    "                                        try:\n",
    "                                            name = p.text.strip()\n",
    "                                        except Exception as e:\n",
    "                                            name = None        \n",
    "                                    if(count == 4):\n",
    "                                        try:\n",
    "                                            status = p.text.strip()\n",
    "                                        except Exception as e:\n",
    "                                            status = None\n",
    "                                    if(count == 12):\n",
    "                                        try:\n",
    "                                            category = p.text.strip()\n",
    "                                        except Exception as e:\n",
    "                                            category = None\n",
    "                                    if(count == 14):\n",
    "                                        try:\n",
    "                                            clas = p.text.strip()\n",
    "                                        except Exception as e:\n",
    "                                            clas = None\n",
    "                                    if(count == 18):\n",
    "                                        try:\n",
    "                                            age = p.text.strip()\n",
    "                                        except Exception as e:\n",
    "                                            age = None\n",
    "                                    if(count == 20):\n",
    "                                        try:\n",
    "                                            sector = p.text.strip().upper()\n",
    "                                        except Exception as e:\n",
    "                                            sector = None \n",
    "            #Manipulating Data\n",
    "                        manufact = [\"MANUFACTURE\",\"BUILD\",\"METALS\",\"PRODUC\",\"ENGINEERING\"]\n",
    "                        it = [\"COMPUTER\",\"TECH\",\"SOFTWARE\",\"DATA\"]\n",
    "                        real = [\"ESTATE\",\"TERRITOR\"]\n",
    "                        busi = [\"BUSINESS\",\"WHOLESALE\",\"RETAIL\",\"TRADE\",\"SERVICE\"]\n",
    "                        fin = [\"FINANC\",\"INSURANCE\",\"PENSION\",\"DEPOSIT\",\"MONETARY\"]\n",
    "                        recreat = [\"HOTEL\",\"CAMP\",\"TRAVEL\",\"RESTAURANT\",\"BAR\",\"RECREATIONAL\",\"SPORTS\"]\n",
    "                        law = [\"LEGAL\",\"LAW\"]\n",
    "                        edu = [\"EDUCATION\"]\n",
    "                        if any(x in sector for x in manufact):\n",
    "                            sector = \"Manufacturing or Engineering\"\n",
    "                        elif any(x in sector for x in it):\n",
    "                            sector = \"IT\"\n",
    "                        elif any(x in sector for x in real):\n",
    "                            sector = \"Real Estate\"\n",
    "                        elif any(x in sector for x in busi):\n",
    "                            sector = \"Business\"\n",
    "                        elif any(x in sector for x in fin):\n",
    "                            sector = \"Finance\"\n",
    "                        elif any(x in sector for x in recreat):\n",
    "                            sector = \"Recreational Services\"\n",
    "                        elif any(x in sector for x in law):\n",
    "                            sector = \"LAW\"\n",
    "                        elif any(x in sector for x in edu):\n",
    "                            sector = \"Education\"\n",
    "                        else:\n",
    "                            sector = \"Other\"\n",
    "\n",
    "\n",
    "                        count = 0        \n",
    "\n",
    "                        try:\n",
    "                            cin = x.thead.a.text\n",
    "                        except Exception as e:\n",
    "                            cin = None\n",
    "\n",
    "                        y = soup2.find(\"div\", class_ = \"col-12\")\n",
    "                        ps = y.find_all(\"p\")\n",
    "                        for p in ps:\n",
    "                            count = count+1\n",
    "                            if(count == 1):\n",
    "                                try:\n",
    "                                    e = p.text.split()\n",
    "                                    email = e[2].strip()\n",
    "                                except Exception as e:\n",
    "                                    email = None\n",
    "                            if(count == 4):\n",
    "                                try:\n",
    "                                    address = p.text.strip()\n",
    "                                except Exception as e:\n",
    "                                    address = None\n",
    "\n",
    "                        count = 0\n",
    "                        data = data.append({\"Sno.\":value, \"CIN_number\":cin ,\"Name\":name ,\"Status\":status ,\"Address\":address ,\"Email\":email,\"Category\":category,\"Class\":clas,\"Age\":age,\"sector\":sector}, ignore_index = True)\n",
    "                        value = value + 1\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "        #Writing to Excel\n",
    "            book = load_workbook(path)\n",
    "            writer = pd.ExcelWriter(path, engine = 'openpyxl')\n",
    "            writer.book = book\n",
    "            if(j == \"E\"):\n",
    "                data.to_excel(writer, sheet_name = \"1 - 5 crores\", index = False)\n",
    "            if(j == \"F\"):\n",
    "                data.to_excel(writer, sheet_name = \"5 - 25 crores\", index = False)\n",
    "            if(j == \"G\"):\n",
    "                data.to_excel(writer, sheet_name = \"25 - 100 crores\", index = False)\n",
    "            if(j == \"H\"):\n",
    "                data.to_excel(writer, sheet_name = \"100 - 500 crores\", index = False)\n",
    "            if(j == \"I\"):\n",
    "                data.to_excel(writer, sheet_name = \"500 crores+\", index = False)\n",
    "            try:\n",
    "                del book[\"Sheet1\"]\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            writer.save()\n",
    "            writer.close()\n",
    "            data.drop(data.index, inplace=True)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        data.drop(data.index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For single buckets i.e. 1-5 crore using threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xlsxwriter\n",
    "import concurrent.futures\n",
    "from openpyxl import load_workbook\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(url):\n",
    "    url_singlepage_list = []\n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source,\"lxml\")\n",
    "    x = soup.find(\"table\", class_ = \"table table-striped col-md-12 col-sm-12 col-xs-12\")\n",
    "    jobs = x.find_all(\"a\", href = True)\n",
    "    for job in jobs:\n",
    "        link = job[\"href\"]\n",
    "        url_singlepage_list.append(link)\n",
    "    return url_singlepage_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = [\"Sno.\",\"CIN_number\",\"Name\",\"Status\",\"Address\",\"Email\",\"Category\",\"Class\",\"Age\",\"sector\",\"location\"])\n",
    "\n",
    "source = requests.get(\"https://www.zaubacorp.com/company-list/paidup-E-company.html\").text\n",
    "soup = BeautifulSoup(source,\"lxml\")\n",
    "\n",
    "section = soup.find(\"div\", class_ = \"back\")\n",
    "tion = section.find(\"div\", class_ = \"region region-content\")\n",
    "sect = tion.find(\"section\", {\"id\":\"block-system-main\",\"class\":\"block block-system clearfix\"})\n",
    "sec = sect.find(\"div\").find_all(\"div\")\n",
    "\n",
    "b = []\n",
    "for se in sec:\n",
    "    se = se.find_all(\"span\")\n",
    "    for s in se:\n",
    "        b.append(s.text)\n",
    "c = b[0].split(\" \")\n",
    "num = int(c[-1].replace(\",\",\"\"))\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1333\n"
     ]
    }
   ],
   "source": [
    "url_combined_list = []\n",
    "count = 0\n",
    "site = \"https://www.zaubacorp.com/company-list/paidup-E/p-{}-company.html\"\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers = 10) as executor:\n",
    "    all_url = {executor.submit(parse, site.format(i)): i for i in range(1,num+1)}\n",
    "    for urls in concurrent.futures.as_completed(all_url):\n",
    "        data = urls.result()\n",
    "        count = count+1\n",
    "        url_combined_list.extend(data)\n",
    "        clear_output(wait=True)\n",
    "        print(count)\n",
    "textfile = open(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\urls.txt\", \"w\")\n",
    "for element in url_combined_list:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(link):\n",
    "    try:\n",
    "        url = requests.get(link).text\n",
    "        soup = BeautifulSoup(url,\"lxml\")\n",
    "\n",
    "        #Collecting Data\n",
    "        x = soup.find(\"table\", class_ = \"table table-striped\")\n",
    "        body = x.find(\"tbody\")\n",
    "        trs = body.find_all(\"tr\")\n",
    "\n",
    "        count = 0 \n",
    "        for tr in trs:\n",
    "            tds = tr.find_all(\"td\")\n",
    "            for td in tds:\n",
    "                ps = td.find_all(\"p\")\n",
    "                for p in ps:\n",
    "                    count = count+1\n",
    "                    if(count == 2):\n",
    "                        try:\n",
    "                            name = p.text.strip()\n",
    "                        except Exception as e:\n",
    "                            name = None    \n",
    "                    if(count == 4):\n",
    "                        try:\n",
    "                            status = p.text.strip()\n",
    "                        except Exception as e:\n",
    "                            status = None\n",
    "                    if(count == 6):\n",
    "                        try:\n",
    "                            loc = p.text.strip().split(\"-\")[1]\n",
    "                        except Exception as e:\n",
    "                            loc = None\n",
    "                    if(count == 12):\n",
    "                        try:\n",
    "                            category = p.text.strip()\n",
    "                        except Exception as e:\n",
    "                            category = None\n",
    "                    if(count == 14):\n",
    "                        try:\n",
    "                            clas = p.text.strip()\n",
    "                        except Exception as e:\n",
    "                            clas = None\n",
    "                    if(count == 18):\n",
    "                        try:\n",
    "                            age = p.text.strip()\n",
    "                        except Exception as e:\n",
    "                            age = None\n",
    "                    if(count == 20):\n",
    "                        try:\n",
    "                            sector = p.text.strip().upper()\n",
    "                        except Exception as e:\n",
    "                            sector = None \n",
    "        #Manipulating Data\n",
    "        manufact = [\"MANUFACTURE\",\"BUILD\",\"METALS\",\"PRODUC\",\"ENGINEERING\"]\n",
    "        it = [\"COMPUTER\",\"TECH\",\"SOFTWARE\",\"DATA\"]\n",
    "        real = [\"ESTATE\",\"TERRITOR\"]\n",
    "        busi = [\"BUSINESS\",\"WHOLESALE\",\"RETAIL\",\"TRADE\",\"SERVICE\"]\n",
    "        fin = [\"FINANC\",\"INSURANCE\",\"PENSION\",\"DEPOSIT\",\"MONETARY\"]\n",
    "        recreat = [\"HOTEL\",\"CAMP\",\"TRAVEL\",\"RESTAURANT\",\"BAR\",\"RECREATIONAL\",\"SPORTS\"]\n",
    "        law = [\"LEGAL\",\"LAW\"]\n",
    "        edu = [\"EDUCATION\"]\n",
    "        if any(x in sector for x in manufact):\n",
    "            sector = \"Manufacturing or Engineering\"\n",
    "        elif any(x in sector for x in it):\n",
    "            sector = \"IT\"\n",
    "        elif any(x in sector for x in real):\n",
    "            sector = \"Real Estate\"\n",
    "        elif any(x in sector for x in busi):\n",
    "            sector = \"Business\"\n",
    "        elif any(x in sector for x in fin):\n",
    "            sector = \"Finance\"\n",
    "        elif any(x in sector for x in recreat):\n",
    "            sector = \"Recreational Services\"\n",
    "        elif any(x in sector for x in law):\n",
    "            sector = \"LAW\"\n",
    "        elif any(x in sector for x in edu):\n",
    "            sector = \"Education\"\n",
    "        else:\n",
    "            sector = \"Other\"\n",
    "\n",
    "        count = 0        \n",
    "        try:\n",
    "            cin = x.thead.a.text\n",
    "        except Exception as e:\n",
    "            cin = None\n",
    "        y = soup.find(\"div\", class_ = \"col-12\")\n",
    "        ps = y.find_all(\"p\")\n",
    "        for p in ps:\n",
    "            count = count+1\n",
    "            if(count == 1):\n",
    "                try:\n",
    "                    e = p.text.split()\n",
    "                    email = e[2].strip()\n",
    "                except Exception as e:\n",
    "                    email = None\n",
    "            if(count == 4):\n",
    "                try:\n",
    "                    address = p.text.strip()\n",
    "                except Exception as e:\n",
    "                    address = None\n",
    "        row = {\"CIN_number\":cin ,\"Name\":name ,\"Status\":status ,\"Address\":address ,\"Email\":email,\"Category\":category,\"Class\":clas,\"Age\":age,\"sector\":sector,\"location\":loc}\n",
    "        return row\n",
    "    except Exception as e:\n",
    "        row = {\"CIN_number\":None ,\"Name\":None ,\"Status\":None ,\"Address\":None ,\"Email\":None,\"Category\":None,\"Class\":None,\"Age\":None,\"sector\":None,\"location\":None}\n",
    "        return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import lxml\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xlsxwriter\n",
    "import concurrent.futures\n",
    "from openpyxl import load_workbook\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "textfile = open(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\urls.txt\", \"r\")\n",
    "url_combined_list = textfile.read()\n",
    "textfile.close()\n",
    "url_combined_list = url_combined_list.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5000\n",
    "final = [url_combined_list[i * n:(i + 1) * n] for i in range((len(url_combined_list) + n - 1) // n )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2549\n",
      "{'CIN_number': None, 'Name': None, 'Status': None, 'Address': None, 'Email': None, 'Category': None, 'Class': None, 'Age': None, 'sector': None, 'location': None}\n"
     ]
    }
   ],
   "source": [
    "filenum = 0\n",
    "for j in final:\n",
    "    count = 0\n",
    "    df = pd.DataFrame(columns = [\"CIN_number\",\"Name\",\"Status\",\"Address\",\"Email\",\"Category\",\"Class\",\"Age\",\"sector\",\"location\"])\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers = 40) as executor:\n",
    "        results = executor.map(collect,j)\n",
    "        for result in results:\n",
    "            df = df.append(result, ignore_index = True)\n",
    "            clear_output(wait=True)\n",
    "            count = count+1\n",
    "            print(count)\n",
    "            print(result)\n",
    "    filenum = filenum+1\n",
    "    df.to_csv(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\task\\{}.csv\".format(filenum), index = False)\n",
    "    time.sleep(120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = r\"C:\\Users\\jaske\\OneDrive\\Desktop\\task\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "df_merged   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "df_merged.to_csv(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\1_to_5_crore.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
