{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Website 1 - College Dekho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'daman-and-diu': 1, 'dubai': 1, 'andaman_nicobar': 3, 'dadra_and_nagar_haveli': 5, 'arunachal-pradesh': 14, 'sikkim': 15, 'mizoram': 22, 'manipur': 23, 'nagaland': 25, 'tripura': 34, 'meghalaya': 40, 'goa': 56, 'chandigarh': 66, 'pondicherry': 82, 'jammu-kashmir': 163, 'himachal-pradesh': 167, 'jharkhand': 211, 'uttaranchal': 254, 'chhattisgarh': 264, 'assam': 295, 'bihar': 397, 'delhi': 456, 'orissa': 477, 'punjab': 670, 'telangana': 699, 'rajasthan': 835, 'haryana': 870, 'madhya-pradesh': 888, 'kerala': 926, 'gujarat': 955, 'west-bengal': 1104, 'andhra-pradesh': 1232, 'karnataka': 1598, 'tamil-nadu': 2033, 'uttar-pradesh': 2368, 'maharashtra': 2783}\n"
     ]
    }
   ],
   "source": [
    "#Getting all the States Data\n",
    "data = pd.read_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\NGO\\Data\\states.xlsx\")\n",
    "data[\"states\"] = data[\"states\"].str.lower()\n",
    "diction = dict(zip(data.states, data.number))\n",
    "print(diction)\n",
    "diction = {'maharashtra': 2783}\n",
    "a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction for Collecting the Links\n",
    "def linkinfo():    \n",
    "    body = driver.find_elements_by_class_name(\"box\")\n",
    "    for b in body:\n",
    "        title = b.find_elements_by_class_name(\"title\")\n",
    "        for t in title:\n",
    "            links = t.find_elements_by_tag_name(\"a\")\n",
    "            for link in links:\n",
    "                a.append(link.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maharashtra\n"
     ]
    }
   ],
   "source": [
    "#For looping through the different States\n",
    "for x, y in diction.items():\n",
    "    state = x\n",
    "    loop = y//31\n",
    "    \n",
    "    url = \"https://www.collegedekho.com/colleges-in-{}/\"\n",
    "    chromedriver = r\"C:\\Users\\jaske\\Downloads\\chromedriver_win32\\chromedriver\"\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(url.format(state)) \n",
    "\n",
    "    count = 0\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"loadmorebtn\")\n",
    "    except Exception as e:\n",
    "        count = 1\n",
    "\n",
    "    if(count == 0):\n",
    "        loadingButton = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"loadMoreButton\"]')))\n",
    "        for i in range(1,loop+2):\n",
    "            driver.execute_script(\"arguments[0].click();\", loadingButton)\n",
    "            time.sleep(2)\n",
    "            WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"loadMoreButton\"]')))\n",
    "    \n",
    "    #Calling the Functions\n",
    "    linkinfo()\n",
    "    driver.close()\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making empty DataFrame\n",
    "frame = pd.DataFrame(columns = [\"name\", \"courses\", \"contact\", \"email\", \"website\", \"address\",\"type\"])\n",
    "\n",
    "#Collecting Main Information\n",
    "for i in a:\n",
    "    html = requests.get(i).text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    #Finding Name\n",
    "    head = soup.find(\"div\", class_ = \"header collegeDetails\")\n",
    "    try:\n",
    "        typ = head.find(\"ul\", class_=\"breadcrumb\").find(\"li\", class_=\"bc-item\").text\n",
    "    except Exception as e:\n",
    "        typ = \"\"     \n",
    "    try:\n",
    "        name = head.find(\"h1\", class_ = \"tooltip\").text.strip()\n",
    "        name = name.splitlines()\n",
    "        name = name[0]\n",
    "    except Exception as e:\n",
    "        name = \"\"\n",
    "    \n",
    "    #Finding Other INFO\n",
    "    body = soup.find(\"div\", class_ = \"block collegeContactBlock\")\n",
    "    f = b = c = d = 0\n",
    "    lists = []\n",
    "    try:\n",
    "        main = body. find(\"div\", class_ = \"collegeAddress\")\n",
    "        li = main.find_all(\"li\")\n",
    "        \n",
    "        for l in li:\n",
    "            data = l.find_all(\"div\", class_ = \"data\")\n",
    "            for da in data:\n",
    "                lists.append(da.text.strip())\n",
    "        \n",
    "        for l in li:\n",
    "            caption = l.find_all(\"div\", class_ = \"label\")\n",
    "            for cap in caption:\n",
    "                if(cap.text.strip() == \"Contact No:\"):\n",
    "                    f = 1\n",
    "                elif(cap.text.strip() == \"Email ID:\"):\n",
    "                    b = 1\n",
    "                elif(cap.text.strip() == \"Website:\"):\n",
    "                    c = 1\n",
    "                elif(cap.text.strip() == \"Address:\"):\n",
    "                    d = 1\n",
    "        \n",
    "        if(f == 1):\n",
    "            contact = lists[0]\n",
    "            lists.pop(0)\n",
    "        else:\n",
    "            contact = \"\"\n",
    "        if(b == 1):\n",
    "            email = lists[0]\n",
    "            lists.pop(0)\n",
    "        else:\n",
    "            email = \"\"\n",
    "        if(c == 1):\n",
    "            website = lists[0]\n",
    "            lists.pop(0)\n",
    "        else:\n",
    "            website = \"\"\n",
    "        if(d == 1):\n",
    "            address = lists[0]\n",
    "            lists.pop(0)\n",
    "        else:\n",
    "            address = \"\"\n",
    "    except Exception as e:\n",
    "        None\n",
    "    \n",
    "    \n",
    "    #Finding Course\n",
    "    cour = \"\"\n",
    "    try:\n",
    "        courses = soup.find(\"table\", class_ = \"couresList\")\n",
    "        course = courses.find_all(\"td\", class_ = \"courseName\")\n",
    "        for c in course:\n",
    "            for i in c.find(\"a\"):\n",
    "                cour = cour+\",\"+i\n",
    "    except Exception as e:\n",
    "        cour = \",None\"\n",
    "    cour = cour[1:]\n",
    "    \n",
    "    #Appending information to the DataFrame\n",
    "    frame = frame.append({\"name\":name, \"courses\":cour, \"contact\":contact, \"email\":email, \"website\":website, \"address\":address, \"type\":typ}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving to an Excel\n",
    "frame.to_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\Colleges6.xlsx\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "main = pd.DataFrame(columns = [\"name\",\"courses\",\"contact\",\"email\",\"website\",\"address\",\"type\"])\n",
    "path = r\"C:\\Users\\jaske\\OneDrive\\Desktop\\folder\"\n",
    "arr = os.listdir(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\folder\")\n",
    "for i in arr:\n",
    "    df = pd.read_excel(path+\"\\\\\"+i)\n",
    "    main = main.append(df, ignore_index = True)\n",
    "main = main.drop_duplicates()\n",
    "main.to_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\final.xlsx\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# College 2 - education-india"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://education-india.in/Education/Colleges/?PageNumber={}\"\n",
    "siteurl = \"http://education-india.in/Education/Colleges/\"\n",
    "a = []\n",
    "for i in range(0,180):\n",
    "    html = requests.get(url.format(i)).text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    main = soup.find(\"table\", class_ = \"index\")\n",
    "    links = main.find_all(\"a\")\n",
    "    for link in links:\n",
    "        if(\"CollegeId\" in link.attrs[\"href\"]):\n",
    "            a.append(siteurl + link.attrs[\"href\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Name\", \"Email\"])\n",
    "for i in a:\n",
    "    html = requests.get(i).text\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    main = soup.find(\"table\", class_ = \"detail\")\n",
    "    name = main.find(\"th\").text.strip().replace(\" Details\",\"\")\n",
    "    links = main.find_all(\"a\")\n",
    "    for link in links:\n",
    "        if(\"mailto\" in link.attrs[\"href\"]):\n",
    "            email = link.attrs[\"href\"].replace(\"mailto:\", \"\")\n",
    "    df = df.append({\"Name\":name, \"Email\":email}, ignore_index = True)\n",
    "df.to_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\data3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "df = pd.read_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\collegedata2.xlsx\")\n",
    "df1 = df.dropna()\n",
    "df1.drop_duplicates(keep = False)\n",
    "df1.to_excel(r\"C:\\Users\\jaske\\OneDrive\\Desktop\\collegedata3.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
